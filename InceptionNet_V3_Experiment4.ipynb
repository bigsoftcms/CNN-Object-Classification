{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"InceptionNet_V3_Experiment4.ipynb","provenance":[{"file_id":"1KasBhzhhagErfWXMSIssWySocYjQE-36","timestamp":1593518733805},{"file_id":"16rcinZ6cs2Hz5PfxmTRkv80I0RcrLSQz","timestamp":1593385720912},{"file_id":"1VBW1BvHacLlqk9K6_muRE35buLKYnAfj","timestamp":1593326909191},{"file_id":"1-rY3nnSKV0VEDhyoK9BBmQA5GcXz-Xjr","timestamp":1593308304656},{"file_id":"16gq_cOe2f_PWyMS94N4jJRAyORRbS--S","timestamp":1592605259782}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"TUoU__vMMs-4","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1593684862587,"user_tz":-330,"elapsed":177165,"user":{"displayName":"SUMIT KUMAR Mishra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8L9OOk0XAmThI6JjfNERxhl4nk0tkwomeiGGDcw=s64","userId":"14062024626619512347"}},"outputId":"6db8aa9b-c491-45b8-a790-2eaddd3f619b"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"j2NY9JY-2QCr","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","headers":[["content-type","application/javascript"]],"ok":true,"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":38},"executionInfo":{"elapsed":2917099,"status":"ok","timestamp":1592699793478,"user":{"displayName":"SUMIT KUMAR Mishra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8L9OOk0XAmThI6JjfNERxhl4nk0tkwomeiGGDcw=s64","userId":"14062024626619512347"},"user_tz":-330},"outputId":"4b843176-9028-48d7-b2dc-ad4ff60c136d"},"source":["from google.colab import files\n","uploaded = files.upload()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-f1b211fc-9467-48fe-8917-19f96de36f97\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-f1b211fc-9467-48fe-8917-19f96de36f97\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Cq3pGjc0FxES","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593708970009,"user_tz":-330,"elapsed":5156168,"user":{"displayName":"SUMIT KUMAR Mishra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8L9OOk0XAmThI6JjfNERxhl4nk0tkwomeiGGDcw=s64","userId":"14062024626619512347"}},"outputId":"23f300fd-44f6-4fd2-e982-d9f6c225d16b"},"source":["from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n","import tensorflow.keras as keras\n","from tensorflow.keras import models\n","from tensorflow.keras import layers\n","from tensorflow.keras import optimizers\n","from keras.layers import Dense, Activation, Dropout, Flatten,\\\n"," Conv2D, MaxPooling2D, AveragePooling2D\n","from keras.layers.normalization import BatchNormalization\n","from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import RMSprop, SGD\n","import tensorflow as tf\n","from keras.utils import np_utils\n","from keras.models import load_model\n","from keras.datasets import cifar10\n","from keras.preprocessing import image\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import cv2\n","from keras.applications.vgg16 import VGG16, preprocess_input\n","\n","inception_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n","#resnet_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","# Set Trainable Layer\n","for layer in inception_model.layers:\n","    if isinstance(layer, BatchNormalization):\n","        layer.trainable = True\n","    else:\n","        layer.trainable = False\n","\n","classifier = tf.keras.Sequential()\n","#classifier.add(tf.keras.layers.UpSampling2D(size=(2,2), input_shape=(150, 150, 3)))\n","#classifier.add(tf.keras.layers.UpSampling2D(size=(2,2), input_shape=(150, 150, 3)))\n","#classifier.add(tf.keras.layers.UpSampling2D(size=(2,2), input_shape=(150, 150, 3)))\n","classifier.add(inception_model)\n","#classifier.add(tf.keras.layers.MaxPooling2D(input_shape=(2,2)))\n","classifier.add(tf.keras.layers.Flatten())\n","classifier.add(tf.keras.layers.Dense(512, activation='relu'))\n","classifier.add(tf.keras.layers.Dropout(0.5))\n","classifier.add(tf.keras.layers.BatchNormalization())\n","#classifier.add(tf.keras.layers.Dense(128, activation='relu'))\n","#classifier.add(tf.keras.layers.Dropout(0.5))\n","#classifier.add(tf.keras.layers.BatchNormalization())\n","classifier.add(tf.keras.layers.Dense(5, activation='softmax'))\n","\n","opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n","\n","classifier.compile(loss='categorical_crossentropy',optimizer=RMSprop(0.0001),metrics=['accuracy'])\n","\n","\n","\n","\n","# Part 2 - Fitting the CNN to the images\n","\n","# Data Augmentation\n","train_datagen = ImageDataGenerator( rescale = 1.0/255.,\n","    preprocessing_function=preprocess_input,\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest')\n","\n","# Data Augmentation\n","test_datagen = ImageDataGenerator(rescale = 1.0/255.,)\n","\n","training_set = train_datagen.flow_from_directory('/content/drive/My Drive/Colab Notebooks/Object Classification1/Training Set',\n","                                                 target_size = (150, 150),\n","                                                 batch_size = 8,\n","                                                 class_mode = 'categorical',\n","                                                 shuffle=True)\n","\n","#training_set = train_datagen.flow_from_directory('C:/Users/Sumit/Desktop/Object Classification/Training Set',\n","#                                                 target_size = (224, 224),\n","#                                                 batch_size = 8,\n","#                                                 class_mode = 'categorical')\n","\n","test_set = test_datagen.flow_from_directory('/content/drive/My Drive/Colab Notebooks/Object Classification1/Test Set',\n","                                            target_size = (150, 150),\n","                                            batch_size = 8,\n","                                            class_mode = 'categorical',\n","                                            shuffle=True)\n","\n","#test_set = test_datagen.flow_from_directory('C:/Users/Sumit/Desktop/Object Classification/Test Set',\n","#                                            target_size = (224, 224),\n","#                                            batch_size = 8,\n"," #                                           class_mode = 'categorical')\n","\n","from datetime import datetime\n","from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n","from tensorflow.keras.callbacks import ReduceLROnPlateau\n","\n","#lr_scheduler = LearningRateScheduler(lr_schedule)\n","\n","lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n","                               cooldown=0,\n","                               patience=5,\n","                               min_lr=0.5e-6)\n","\n","#num_epochs = 1000\n","#num_batch_size = 32\n","\n","checkpoint = ModelCheckpoint(filepath='/content/drive/My Drive/Colab Notebooks/Object Classification1/InceptionNet_Experiment4.h5', \n","                               verbose=1, save_best_only=True)\n","\n","#callbacks = [checkpoint, lr_reducer]\n","callbacks = [checkpoint, lr_reducer]\n","\n","\n","start = datetime.now()\n","\n","classifier.summary()\n","\n","model = classifier.fit_generator(training_set,\n","                         steps_per_epoch = 100,\n","                         epochs = 100,\n","                         validation_data = test_set,    \n","                         validation_steps = 10,\n","                         callbacks=callbacks ,verbose=1)\n","duration = datetime.now() - start\n","print(\"Training completed in time: \", duration)\n","\n","classifier.save(\"/content/drive/My Drive/Colab Notebooks/Object Classification1/InceptionNet_Experiment4.h5\")\n","#classifier.save(\"C:/Users/Sumit/Desktop/Object Classification/ResNet50_Experiment1.h5\")\n","print(\"Saved model to disk\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 1278 images belonging to 5 classes.\n","Found 375 images belonging to 5 classes.\n","Model: \"sequential_9\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","inception_v3 (Model)         (None, 3, 3, 2048)        21802784  \n","_________________________________________________________________\n","flatten_9 (Flatten)          (None, 18432)             0         \n","_________________________________________________________________\n","dense_20 (Dense)             (None, 512)               9437696   \n","_________________________________________________________________\n","dropout_11 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","batch_normalization_951 (Bat (None, 512)               2048      \n","_________________________________________________________________\n","dense_21 (Dense)             (None, 5)                 2565      \n","=================================================================\n","Total params: 31,245,093\n","Trainable params: 9,441,285\n","Non-trainable params: 21,803,808\n","_________________________________________________________________\n","Epoch 1/100\n"," 10/100 [==>...........................] - ETA: 38s - loss: 1.3615 - accuracy: 0.4625"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["100/100 [==============================] - ETA: 0s - loss: 0.5495 - accuracy: 0.8012\n","Epoch 00001: val_loss improved from inf to 0.09998, saving model to /content/drive/My Drive/Colab Notebooks/Object Classification1/InceptionNet_Experiment4.h5\n","100/100 [==============================] - 53s 529ms/step - loss: 0.5495 - accuracy: 0.8012 - val_loss: 0.1000 - val_accuracy: 0.9750 - lr: 1.0000e-04\n","Epoch 2/100\n","100/100 [==============================] - ETA: 0s - loss: 0.3326 - accuracy: 0.8847\n","Epoch 00002: val_loss did not improve from 0.09998\n","100/100 [==============================] - 51s 513ms/step - loss: 0.3326 - accuracy: 0.8847 - val_loss: 0.1089 - val_accuracy: 0.9375 - lr: 1.0000e-04\n","Epoch 3/100\n","100/100 [==============================] - ETA: 0s - loss: 0.2637 - accuracy: 0.9135\n","Epoch 00003: val_loss did not improve from 0.09998\n","100/100 [==============================] - 50s 503ms/step - loss: 0.2637 - accuracy: 0.9135 - val_loss: 0.2248 - val_accuracy: 0.9500 - lr: 1.0000e-04\n","Epoch 4/100\n","100/100 [==============================] - ETA: 0s - loss: 0.2132 - accuracy: 0.9400\n","Epoch 00004: val_loss improved from 0.09998 to 0.01733, saving model to /content/drive/My Drive/Colab Notebooks/Object Classification1/InceptionNet_Experiment4.h5\n","100/100 [==============================] - 52s 516ms/step - loss: 0.2132 - accuracy: 0.9400 - val_loss: 0.0173 - val_accuracy: 1.0000 - lr: 1.0000e-04\n","Epoch 5/100\n","100/100 [==============================] - ETA: 0s - loss: 0.2072 - accuracy: 0.9362\n","Epoch 00005: val_loss did not improve from 0.01733\n","100/100 [==============================] - 51s 507ms/step - loss: 0.2072 - accuracy: 0.9362 - val_loss: 0.1037 - val_accuracy: 0.9625 - lr: 1.0000e-04\n","Epoch 6/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1670 - accuracy: 0.9488\n","Epoch 00006: val_loss did not improve from 0.01733\n","100/100 [==============================] - 51s 507ms/step - loss: 0.1670 - accuracy: 0.9488 - val_loss: 0.0700 - val_accuracy: 1.0000 - lr: 1.0000e-04\n","Epoch 7/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1893 - accuracy: 0.9449\n","Epoch 00007: val_loss did not improve from 0.01733\n","100/100 [==============================] - 52s 515ms/step - loss: 0.1893 - accuracy: 0.9449 - val_loss: 0.0831 - val_accuracy: 0.9625 - lr: 1.0000e-04\n","Epoch 8/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1394 - accuracy: 0.9599\n","Epoch 00008: val_loss did not improve from 0.01733\n","100/100 [==============================] - 51s 506ms/step - loss: 0.1394 - accuracy: 0.9599 - val_loss: 0.1072 - val_accuracy: 0.9750 - lr: 1.0000e-04\n","Epoch 9/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1688 - accuracy: 0.9513\n","Epoch 00009: val_loss did not improve from 0.01733\n","100/100 [==============================] - 50s 503ms/step - loss: 0.1688 - accuracy: 0.9513 - val_loss: 0.1465 - val_accuracy: 0.9375 - lr: 1.0000e-04\n","Epoch 10/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1521 - accuracy: 0.9511\n","Epoch 00010: val_loss did not improve from 0.01733\n","100/100 [==============================] - 50s 502ms/step - loss: 0.1521 - accuracy: 0.9511 - val_loss: 0.0810 - val_accuracy: 0.9875 - lr: 3.1623e-05\n","Epoch 11/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1387 - accuracy: 0.9675\n","Epoch 00011: val_loss did not improve from 0.01733\n","100/100 [==============================] - 50s 505ms/step - loss: 0.1387 - accuracy: 0.9675 - val_loss: 0.0237 - val_accuracy: 1.0000 - lr: 3.1623e-05\n","Epoch 12/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1072 - accuracy: 0.9724\n","Epoch 00012: val_loss did not improve from 0.01733\n","100/100 [==============================] - 50s 501ms/step - loss: 0.1072 - accuracy: 0.9724 - val_loss: 0.0663 - val_accuracy: 0.9875 - lr: 3.1623e-05\n","Epoch 13/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1052 - accuracy: 0.9649\n","Epoch 00013: val_loss did not improve from 0.01733\n","100/100 [==============================] - 51s 512ms/step - loss: 0.1052 - accuracy: 0.9649 - val_loss: 0.0307 - val_accuracy: 0.9750 - lr: 3.1623e-05\n","Epoch 14/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1474 - accuracy: 0.9624\n","Epoch 00014: val_loss did not improve from 0.01733\n","100/100 [==============================] - 50s 504ms/step - loss: 0.1474 - accuracy: 0.9624 - val_loss: 0.0436 - val_accuracy: 0.9875 - lr: 3.1623e-05\n","Epoch 15/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1191 - accuracy: 0.9724\n","Epoch 00015: val_loss did not improve from 0.01733\n","100/100 [==============================] - 50s 505ms/step - loss: 0.1191 - accuracy: 0.9724 - val_loss: 0.0561 - val_accuracy: 0.9625 - lr: 1.0000e-05\n","Epoch 16/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1059 - accuracy: 0.9762\n","Epoch 00016: val_loss did not improve from 0.01733\n","100/100 [==============================] - 50s 504ms/step - loss: 0.1059 - accuracy: 0.9762 - val_loss: 0.0553 - val_accuracy: 0.9625 - lr: 1.0000e-05\n","Epoch 17/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1093 - accuracy: 0.9675\n","Epoch 00017: val_loss did not improve from 0.01733\n","100/100 [==============================] - 50s 504ms/step - loss: 0.1093 - accuracy: 0.9675 - val_loss: 0.0477 - val_accuracy: 0.9875 - lr: 1.0000e-05\n","Epoch 18/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0955 - accuracy: 0.9699\n","Epoch 00018: val_loss did not improve from 0.01733\n","100/100 [==============================] - 50s 504ms/step - loss: 0.0955 - accuracy: 0.9699 - val_loss: 0.1105 - val_accuracy: 0.9750 - lr: 1.0000e-05\n","Epoch 19/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0953 - accuracy: 0.9825\n","Epoch 00019: val_loss improved from 0.01733 to 0.00617, saving model to /content/drive/My Drive/Colab Notebooks/Object Classification1/InceptionNet_Experiment4.h5\n","100/100 [==============================] - 53s 529ms/step - loss: 0.0953 - accuracy: 0.9825 - val_loss: 0.0062 - val_accuracy: 1.0000 - lr: 1.0000e-05\n","Epoch 20/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1052 - accuracy: 0.9624\n","Epoch 00020: val_loss did not improve from 0.00617\n","100/100 [==============================] - 51s 514ms/step - loss: 0.1052 - accuracy: 0.9624 - val_loss: 0.0525 - val_accuracy: 0.9750 - lr: 1.0000e-05\n","Epoch 21/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0890 - accuracy: 0.9762\n","Epoch 00021: val_loss did not improve from 0.00617\n","100/100 [==============================] - 51s 511ms/step - loss: 0.0890 - accuracy: 0.9762 - val_loss: 0.1719 - val_accuracy: 0.9125 - lr: 1.0000e-05\n","Epoch 22/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0916 - accuracy: 0.9775\n","Epoch 00022: val_loss did not improve from 0.00617\n","100/100 [==============================] - 51s 506ms/step - loss: 0.0916 - accuracy: 0.9775 - val_loss: 0.0796 - val_accuracy: 0.9625 - lr: 1.0000e-05\n","Epoch 23/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0996 - accuracy: 0.9649\n","Epoch 00023: val_loss did not improve from 0.00617\n","100/100 [==============================] - 50s 505ms/step - loss: 0.0996 - accuracy: 0.9649 - val_loss: 0.1932 - val_accuracy: 0.9375 - lr: 1.0000e-05\n","Epoch 24/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0975 - accuracy: 0.9787\n","Epoch 00024: val_loss did not improve from 0.00617\n","100/100 [==============================] - 50s 503ms/step - loss: 0.0975 - accuracy: 0.9787 - val_loss: 0.0197 - val_accuracy: 0.9875 - lr: 1.0000e-05\n","Epoch 25/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1053 - accuracy: 0.9662\n","Epoch 00025: val_loss did not improve from 0.00617\n","100/100 [==============================] - 51s 507ms/step - loss: 0.1053 - accuracy: 0.9662 - val_loss: 0.0844 - val_accuracy: 0.9750 - lr: 3.1623e-06\n","Epoch 26/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1080 - accuracy: 0.9699\n","Epoch 00026: val_loss did not improve from 0.00617\n","100/100 [==============================] - 50s 501ms/step - loss: 0.1080 - accuracy: 0.9699 - val_loss: 0.1432 - val_accuracy: 0.9625 - lr: 3.1623e-06\n","Epoch 27/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0993 - accuracy: 0.9700\n","Epoch 00027: val_loss did not improve from 0.00617\n","100/100 [==============================] - 50s 500ms/step - loss: 0.0993 - accuracy: 0.9700 - val_loss: 0.0730 - val_accuracy: 0.9750 - lr: 3.1623e-06\n","Epoch 28/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0932 - accuracy: 0.9737\n","Epoch 00028: val_loss did not improve from 0.00617\n","100/100 [==============================] - 50s 505ms/step - loss: 0.0932 - accuracy: 0.9737 - val_loss: 0.0841 - val_accuracy: 0.9625 - lr: 3.1623e-06\n","Epoch 29/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 0.9613\n","Epoch 00029: val_loss did not improve from 0.00617\n","100/100 [==============================] - 50s 500ms/step - loss: 0.1138 - accuracy: 0.9613 - val_loss: 0.0582 - val_accuracy: 0.9750 - lr: 3.1623e-06\n","Epoch 30/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0902 - accuracy: 0.9737\n","Epoch 00030: val_loss did not improve from 0.00617\n","100/100 [==============================] - 50s 504ms/step - loss: 0.0902 - accuracy: 0.9737 - val_loss: 0.0605 - val_accuracy: 0.9750 - lr: 1.0000e-06\n","Epoch 31/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0990 - accuracy: 0.9737\n","Epoch 00031: val_loss did not improve from 0.00617\n","100/100 [==============================] - 50s 499ms/step - loss: 0.0990 - accuracy: 0.9737 - val_loss: 0.0977 - val_accuracy: 0.9750 - lr: 1.0000e-06\n","Epoch 32/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1013 - accuracy: 0.9649\n","Epoch 00032: val_loss did not improve from 0.00617\n","100/100 [==============================] - 50s 496ms/step - loss: 0.1013 - accuracy: 0.9649 - val_loss: 0.0299 - val_accuracy: 0.9875 - lr: 1.0000e-06\n","Epoch 33/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1196 - accuracy: 0.9599\n","Epoch 00033: val_loss did not improve from 0.00617\n","100/100 [==============================] - 50s 499ms/step - loss: 0.1196 - accuracy: 0.9599 - val_loss: 0.1251 - val_accuracy: 0.9750 - lr: 1.0000e-06\n","Epoch 34/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0840 - accuracy: 0.9725\n","Epoch 00034: val_loss did not improve from 0.00617\n","100/100 [==============================] - 50s 502ms/step - loss: 0.0840 - accuracy: 0.9725 - val_loss: 0.0935 - val_accuracy: 0.9750 - lr: 1.0000e-06\n","Epoch 35/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1037 - accuracy: 0.9649\n","Epoch 00035: val_loss did not improve from 0.00617\n","100/100 [==============================] - 51s 506ms/step - loss: 0.1037 - accuracy: 0.9649 - val_loss: 0.0294 - val_accuracy: 0.9875 - lr: 5.0000e-07\n","Epoch 36/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1333 - accuracy: 0.9612\n","Epoch 00036: val_loss did not improve from 0.00617\n","100/100 [==============================] - 50s 504ms/step - loss: 0.1333 - accuracy: 0.9612 - val_loss: 0.0494 - val_accuracy: 0.9875 - lr: 5.0000e-07\n","Epoch 37/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1131 - accuracy: 0.9649\n","Epoch 00037: val_loss did not improve from 0.00617\n","100/100 [==============================] - 51s 510ms/step - loss: 0.1131 - accuracy: 0.9649 - val_loss: 0.0765 - val_accuracy: 0.9750 - lr: 5.0000e-07\n","Epoch 38/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0904 - accuracy: 0.9749\n","Epoch 00038: val_loss did not improve from 0.00617\n","100/100 [==============================] - 50s 504ms/step - loss: 0.0904 - accuracy: 0.9749 - val_loss: 0.0744 - val_accuracy: 0.9750 - lr: 5.0000e-07\n","Epoch 39/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0847 - accuracy: 0.9737\n","Epoch 00039: val_loss did not improve from 0.00617\n","100/100 [==============================] - 50s 504ms/step - loss: 0.0847 - accuracy: 0.9737 - val_loss: 0.0280 - val_accuracy: 1.0000 - lr: 5.0000e-07\n","Epoch 40/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0978 - accuracy: 0.9737\n","Epoch 00040: val_loss did not improve from 0.00617\n","100/100 [==============================] - 50s 503ms/step - loss: 0.0978 - accuracy: 0.9737 - val_loss: 0.0579 - val_accuracy: 0.9875 - lr: 5.0000e-07\n","Epoch 41/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0791 - accuracy: 0.9812\n","Epoch 00041: val_loss did not improve from 0.00617\n","100/100 [==============================] - 51s 506ms/step - loss: 0.0791 - accuracy: 0.9812 - val_loss: 0.0238 - val_accuracy: 1.0000 - lr: 5.0000e-07\n","Epoch 42/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0846 - accuracy: 0.9774\n","Epoch 00042: val_loss did not improve from 0.00617\n","100/100 [==============================] - 51s 510ms/step - loss: 0.0846 - accuracy: 0.9774 - val_loss: 0.0491 - val_accuracy: 0.9750 - lr: 5.0000e-07\n","Epoch 43/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.9762\n","Epoch 00043: val_loss did not improve from 0.00617\n","100/100 [==============================] - 50s 504ms/step - loss: 0.0798 - accuracy: 0.9762 - val_loss: 0.0352 - val_accuracy: 0.9875 - lr: 5.0000e-07\n","Epoch 44/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1031 - accuracy: 0.9674\n","Epoch 00044: val_loss did not improve from 0.00617\n","100/100 [==============================] - 50s 503ms/step - loss: 0.1031 - accuracy: 0.9674 - val_loss: 0.0742 - val_accuracy: 0.9625 - lr: 5.0000e-07\n","Epoch 45/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0925 - accuracy: 0.9737\n","Epoch 00045: val_loss did not improve from 0.00617\n","100/100 [==============================] - 50s 502ms/step - loss: 0.0925 - accuracy: 0.9737 - val_loss: 0.0649 - val_accuracy: 0.9875 - lr: 5.0000e-07\n","Epoch 46/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0934 - accuracy: 0.9762\n","Epoch 00046: val_loss did not improve from 0.00617\n","100/100 [==============================] - 51s 506ms/step - loss: 0.0934 - accuracy: 0.9762 - val_loss: 0.0509 - val_accuracy: 0.9750 - lr: 5.0000e-07\n","Epoch 47/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1011 - accuracy: 0.9663\n","Epoch 00047: val_loss did not improve from 0.00617\n","100/100 [==============================] - 50s 504ms/step - loss: 0.1011 - accuracy: 0.9663 - val_loss: 0.0126 - val_accuracy: 1.0000 - lr: 5.0000e-07\n","Epoch 48/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1004 - accuracy: 0.9724\n","Epoch 00048: val_loss did not improve from 0.00617\n","100/100 [==============================] - 50s 505ms/step - loss: 0.1004 - accuracy: 0.9724 - val_loss: 0.0770 - val_accuracy: 0.9875 - lr: 5.0000e-07\n","Epoch 49/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0717 - accuracy: 0.9837\n","Epoch 00049: val_loss did not improve from 0.00617\n","100/100 [==============================] - 51s 506ms/step - loss: 0.0717 - accuracy: 0.9837 - val_loss: 0.0371 - val_accuracy: 0.9875 - lr: 5.0000e-07\n","Epoch 50/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 0.9825\n","Epoch 00050: val_loss did not improve from 0.00617\n","100/100 [==============================] - 51s 510ms/step - loss: 0.0700 - accuracy: 0.9825 - val_loss: 0.1484 - val_accuracy: 0.9625 - lr: 5.0000e-07\n","Epoch 51/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1009 - accuracy: 0.9712\n","Epoch 00051: val_loss did not improve from 0.00617\n","100/100 [==============================] - 50s 504ms/step - loss: 0.1009 - accuracy: 0.9712 - val_loss: 0.0514 - val_accuracy: 0.9875 - lr: 5.0000e-07\n","Epoch 52/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1337 - accuracy: 0.9536\n","Epoch 00052: val_loss improved from 0.00617 to 0.00475, saving model to /content/drive/My Drive/Colab Notebooks/Object Classification1/InceptionNet_Experiment4.h5\n","100/100 [==============================] - 54s 540ms/step - loss: 0.1337 - accuracy: 0.9536 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 5.0000e-07\n","Epoch 53/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0713 - accuracy: 0.9850\n","Epoch 00053: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 513ms/step - loss: 0.0713 - accuracy: 0.9850 - val_loss: 0.0889 - val_accuracy: 0.9750 - lr: 5.0000e-07\n","Epoch 54/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1095 - accuracy: 0.9650\n","Epoch 00054: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 506ms/step - loss: 0.1095 - accuracy: 0.9650 - val_loss: 0.0728 - val_accuracy: 0.9750 - lr: 5.0000e-07\n","Epoch 55/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1078 - accuracy: 0.9687\n","Epoch 00055: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 505ms/step - loss: 0.1078 - accuracy: 0.9687 - val_loss: 0.0388 - val_accuracy: 0.9750 - lr: 5.0000e-07\n","Epoch 56/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0901 - accuracy: 0.9700\n","Epoch 00056: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 508ms/step - loss: 0.0901 - accuracy: 0.9700 - val_loss: 0.0430 - val_accuracy: 0.9875 - lr: 5.0000e-07\n","Epoch 57/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1098 - accuracy: 0.9649\n","Epoch 00057: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 510ms/step - loss: 0.1098 - accuracy: 0.9649 - val_loss: 0.0407 - val_accuracy: 0.9875 - lr: 5.0000e-07\n","Epoch 58/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1180 - accuracy: 0.9663\n","Epoch 00058: val_loss did not improve from 0.00475\n","100/100 [==============================] - 52s 516ms/step - loss: 0.1180 - accuracy: 0.9663 - val_loss: 0.0668 - val_accuracy: 0.9750 - lr: 5.0000e-07\n","Epoch 59/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0917 - accuracy: 0.9749\n","Epoch 00059: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 506ms/step - loss: 0.0917 - accuracy: 0.9749 - val_loss: 0.0714 - val_accuracy: 0.9625 - lr: 5.0000e-07\n","Epoch 60/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0866 - accuracy: 0.9774\n","Epoch 00060: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 507ms/step - loss: 0.0866 - accuracy: 0.9774 - val_loss: 0.0404 - val_accuracy: 0.9750 - lr: 5.0000e-07\n","Epoch 61/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1146 - accuracy: 0.9700\n","Epoch 00061: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 513ms/step - loss: 0.1146 - accuracy: 0.9700 - val_loss: 0.0674 - val_accuracy: 0.9875 - lr: 5.0000e-07\n","Epoch 62/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0995 - accuracy: 0.9762\n","Epoch 00062: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 506ms/step - loss: 0.0995 - accuracy: 0.9762 - val_loss: 0.0975 - val_accuracy: 0.9750 - lr: 5.0000e-07\n","Epoch 63/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0611 - accuracy: 0.9825\n","Epoch 00063: val_loss did not improve from 0.00475\n","100/100 [==============================] - 50s 501ms/step - loss: 0.0611 - accuracy: 0.9825 - val_loss: 0.0483 - val_accuracy: 0.9875 - lr: 5.0000e-07\n","Epoch 64/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.9688\n","Epoch 00064: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 506ms/step - loss: 0.0919 - accuracy: 0.9688 - val_loss: 0.1503 - val_accuracy: 0.9625 - lr: 5.0000e-07\n","Epoch 65/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0936 - accuracy: 0.9787\n","Epoch 00065: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 507ms/step - loss: 0.0936 - accuracy: 0.9787 - val_loss: 0.0200 - val_accuracy: 1.0000 - lr: 5.0000e-07\n","Epoch 66/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1131 - accuracy: 0.9649\n","Epoch 00066: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 506ms/step - loss: 0.1131 - accuracy: 0.9649 - val_loss: 0.0437 - val_accuracy: 0.9750 - lr: 5.0000e-07\n","Epoch 67/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0812 - accuracy: 0.9812\n","Epoch 00067: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 507ms/step - loss: 0.0812 - accuracy: 0.9812 - val_loss: 0.1028 - val_accuracy: 0.9500 - lr: 5.0000e-07\n","Epoch 68/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0927 - accuracy: 0.9712\n","Epoch 00068: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 508ms/step - loss: 0.0927 - accuracy: 0.9712 - val_loss: 0.0244 - val_accuracy: 1.0000 - lr: 5.0000e-07\n","Epoch 69/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1012 - accuracy: 0.9674\n","Epoch 00069: val_loss did not improve from 0.00475\n","100/100 [==============================] - 50s 502ms/step - loss: 0.1012 - accuracy: 0.9674 - val_loss: 0.0405 - val_accuracy: 0.9875 - lr: 5.0000e-07\n","Epoch 70/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0969 - accuracy: 0.9749\n","Epoch 00070: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 506ms/step - loss: 0.0969 - accuracy: 0.9749 - val_loss: 0.0253 - val_accuracy: 1.0000 - lr: 5.0000e-07\n","Epoch 71/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.9724\n","Epoch 00071: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 508ms/step - loss: 0.0865 - accuracy: 0.9724 - val_loss: 0.0316 - val_accuracy: 1.0000 - lr: 5.0000e-07\n","Epoch 72/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0916 - accuracy: 0.9762\n","Epoch 00072: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 509ms/step - loss: 0.0916 - accuracy: 0.9762 - val_loss: 0.0610 - val_accuracy: 0.9875 - lr: 5.0000e-07\n","Epoch 73/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1176 - accuracy: 0.9699\n","Epoch 00073: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 513ms/step - loss: 0.1176 - accuracy: 0.9699 - val_loss: 0.0489 - val_accuracy: 0.9875 - lr: 5.0000e-07\n","Epoch 74/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0956 - accuracy: 0.9712\n","Epoch 00074: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 507ms/step - loss: 0.0956 - accuracy: 0.9712 - val_loss: 0.0576 - val_accuracy: 0.9875 - lr: 5.0000e-07\n","Epoch 75/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0845 - accuracy: 0.9787\n","Epoch 00075: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 506ms/step - loss: 0.0845 - accuracy: 0.9787 - val_loss: 0.1193 - val_accuracy: 0.9625 - lr: 5.0000e-07\n","Epoch 76/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0961 - accuracy: 0.9737\n","Epoch 00076: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 509ms/step - loss: 0.0961 - accuracy: 0.9737 - val_loss: 0.0950 - val_accuracy: 0.9750 - lr: 5.0000e-07\n","Epoch 77/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0917 - accuracy: 0.9749\n","Epoch 00077: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 507ms/step - loss: 0.0917 - accuracy: 0.9749 - val_loss: 0.0777 - val_accuracy: 0.9750 - lr: 5.0000e-07\n","Epoch 78/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0907 - accuracy: 0.9774\n","Epoch 00078: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 509ms/step - loss: 0.0907 - accuracy: 0.9774 - val_loss: 0.0078 - val_accuracy: 1.0000 - lr: 5.0000e-07\n","Epoch 79/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0792 - accuracy: 0.9825\n","Epoch 00079: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 511ms/step - loss: 0.0792 - accuracy: 0.9825 - val_loss: 0.0992 - val_accuracy: 0.9750 - lr: 5.0000e-07\n","Epoch 80/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1188 - accuracy: 0.9650\n","Epoch 00080: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 513ms/step - loss: 0.1188 - accuracy: 0.9650 - val_loss: 0.0750 - val_accuracy: 0.9750 - lr: 5.0000e-07\n","Epoch 81/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0940 - accuracy: 0.9750\n","Epoch 00081: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 508ms/step - loss: 0.0940 - accuracy: 0.9750 - val_loss: 0.0383 - val_accuracy: 0.9750 - lr: 5.0000e-07\n","Epoch 82/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0572 - accuracy: 0.9837\n","Epoch 00082: val_loss did not improve from 0.00475\n","100/100 [==============================] - 52s 517ms/step - loss: 0.0572 - accuracy: 0.9837 - val_loss: 0.0498 - val_accuracy: 0.9875 - lr: 5.0000e-07\n","Epoch 83/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 0.9762\n","Epoch 00083: val_loss did not improve from 0.00475\n","100/100 [==============================] - 50s 504ms/step - loss: 0.0795 - accuracy: 0.9762 - val_loss: 0.0511 - val_accuracy: 0.9875 - lr: 5.0000e-07\n","Epoch 84/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0935 - accuracy: 0.9762\n","Epoch 00084: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 506ms/step - loss: 0.0935 - accuracy: 0.9762 - val_loss: 0.0398 - val_accuracy: 0.9750 - lr: 5.0000e-07\n","Epoch 85/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1081 - accuracy: 0.9663\n","Epoch 00085: val_loss did not improve from 0.00475\n","100/100 [==============================] - 52s 516ms/step - loss: 0.1081 - accuracy: 0.9663 - val_loss: 0.0652 - val_accuracy: 0.9875 - lr: 5.0000e-07\n","Epoch 86/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0926 - accuracy: 0.9749\n","Epoch 00086: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 511ms/step - loss: 0.0926 - accuracy: 0.9749 - val_loss: 0.0378 - val_accuracy: 0.9750 - lr: 5.0000e-07\n","Epoch 87/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0972 - accuracy: 0.9675\n","Epoch 00087: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 511ms/step - loss: 0.0972 - accuracy: 0.9675 - val_loss: 0.0556 - val_accuracy: 0.9875 - lr: 5.0000e-07\n","Epoch 88/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0872 - accuracy: 0.9762\n","Epoch 00088: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 507ms/step - loss: 0.0872 - accuracy: 0.9762 - val_loss: 0.0399 - val_accuracy: 0.9875 - lr: 5.0000e-07\n","Epoch 89/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0731 - accuracy: 0.9862\n","Epoch 00089: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 509ms/step - loss: 0.0731 - accuracy: 0.9862 - val_loss: 0.1254 - val_accuracy: 0.9500 - lr: 5.0000e-07\n","Epoch 90/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1045 - accuracy: 0.9663\n","Epoch 00090: val_loss did not improve from 0.00475\n","100/100 [==============================] - 50s 503ms/step - loss: 0.1045 - accuracy: 0.9663 - val_loss: 0.0593 - val_accuracy: 0.9750 - lr: 5.0000e-07\n","Epoch 91/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1065 - accuracy: 0.9662\n","Epoch 00091: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 509ms/step - loss: 0.1065 - accuracy: 0.9662 - val_loss: 0.0699 - val_accuracy: 0.9750 - lr: 5.0000e-07\n","Epoch 92/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1196 - accuracy: 0.9613\n","Epoch 00092: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 512ms/step - loss: 0.1196 - accuracy: 0.9613 - val_loss: 0.0143 - val_accuracy: 1.0000 - lr: 5.0000e-07\n","Epoch 93/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0752 - accuracy: 0.9762\n","Epoch 00093: val_loss did not improve from 0.00475\n","100/100 [==============================] - 52s 520ms/step - loss: 0.0752 - accuracy: 0.9762 - val_loss: 0.0108 - val_accuracy: 1.0000 - lr: 5.0000e-07\n","Epoch 94/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0800 - accuracy: 0.9762\n","Epoch 00094: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 508ms/step - loss: 0.0800 - accuracy: 0.9762 - val_loss: 0.0864 - val_accuracy: 0.9750 - lr: 5.0000e-07\n","Epoch 95/100\n","100/100 [==============================] - ETA: 0s - loss: 0.1009 - accuracy: 0.9712\n","Epoch 00095: val_loss did not improve from 0.00475\n","100/100 [==============================] - 50s 502ms/step - loss: 0.1009 - accuracy: 0.9712 - val_loss: 0.0637 - val_accuracy: 0.9875 - lr: 5.0000e-07\n","Epoch 96/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.9875\n","Epoch 00096: val_loss did not improve from 0.00475\n","100/100 [==============================] - 50s 504ms/step - loss: 0.0632 - accuracy: 0.9875 - val_loss: 0.0514 - val_accuracy: 0.9875 - lr: 5.0000e-07\n","Epoch 97/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0863 - accuracy: 0.9737\n","Epoch 00097: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 512ms/step - loss: 0.0863 - accuracy: 0.9737 - val_loss: 0.0660 - val_accuracy: 0.9875 - lr: 5.0000e-07\n","Epoch 98/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0998 - accuracy: 0.9724\n","Epoch 00098: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 508ms/step - loss: 0.0998 - accuracy: 0.9724 - val_loss: 0.0221 - val_accuracy: 1.0000 - lr: 5.0000e-07\n","Epoch 99/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0958 - accuracy: 0.9750\n","Epoch 00099: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 508ms/step - loss: 0.0958 - accuracy: 0.9750 - val_loss: 0.0667 - val_accuracy: 0.9875 - lr: 5.0000e-07\n","Epoch 100/100\n","100/100 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.9787\n","Epoch 00100: val_loss did not improve from 0.00475\n","100/100 [==============================] - 51s 507ms/step - loss: 0.0919 - accuracy: 0.9787 - val_loss: 0.0362 - val_accuracy: 0.9750 - lr: 5.0000e-07\n","Training completed in time:  1:25:40.342420\n","Saved model to disk\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qAMJ1ryKcy7y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1593328772807,"user_tz":-330,"elapsed":925,"user":{"displayName":"SUMIT KUMAR Mishra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8L9OOk0XAmThI6JjfNERxhl4nk0tkwomeiGGDcw=s64","userId":"14062024626619512347"}},"outputId":"dfabd3d3-0d80-4b1a-fde4-8d1b3ddf32db"},"source":["+inception_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"inception_v3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_4 (InputLayer)            [(None, 224, 224, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv2d_282 (Conv2D)             (None, 111, 111, 32) 864         input_4[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_284 (BatchN (None, 111, 111, 32) 96          conv2d_282[0][0]                 \n","__________________________________________________________________________________________________\n","activation_282 (Activation)     (None, 111, 111, 32) 0           batch_normalization_284[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_283 (Conv2D)             (None, 109, 109, 32) 9216        activation_282[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_285 (BatchN (None, 109, 109, 32) 96          conv2d_283[0][0]                 \n","__________________________________________________________________________________________________\n","activation_283 (Activation)     (None, 109, 109, 32) 0           batch_normalization_285[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_284 (Conv2D)             (None, 109, 109, 64) 18432       activation_283[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_286 (BatchN (None, 109, 109, 64) 192         conv2d_284[0][0]                 \n","__________________________________________________________________________________________________\n","activation_284 (Activation)     (None, 109, 109, 64) 0           batch_normalization_286[0][0]    \n","__________________________________________________________________________________________________\n","max_pooling2d_12 (MaxPooling2D) (None, 54, 54, 64)   0           activation_284[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_285 (Conv2D)             (None, 54, 54, 80)   5120        max_pooling2d_12[0][0]           \n","__________________________________________________________________________________________________\n","batch_normalization_287 (BatchN (None, 54, 54, 80)   240         conv2d_285[0][0]                 \n","__________________________________________________________________________________________________\n","activation_285 (Activation)     (None, 54, 54, 80)   0           batch_normalization_287[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_286 (Conv2D)             (None, 52, 52, 192)  138240      activation_285[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_288 (BatchN (None, 52, 52, 192)  576         conv2d_286[0][0]                 \n","__________________________________________________________________________________________________\n","activation_286 (Activation)     (None, 52, 52, 192)  0           batch_normalization_288[0][0]    \n","__________________________________________________________________________________________________\n","max_pooling2d_13 (MaxPooling2D) (None, 25, 25, 192)  0           activation_286[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_290 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_13[0][0]           \n","__________________________________________________________________________________________________\n","batch_normalization_292 (BatchN (None, 25, 25, 64)   192         conv2d_290[0][0]                 \n","__________________________________________________________________________________________________\n","activation_290 (Activation)     (None, 25, 25, 64)   0           batch_normalization_292[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_288 (Conv2D)             (None, 25, 25, 48)   9216        max_pooling2d_13[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_291 (Conv2D)             (None, 25, 25, 96)   55296       activation_290[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_290 (BatchN (None, 25, 25, 48)   144         conv2d_288[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_293 (BatchN (None, 25, 25, 96)   288         conv2d_291[0][0]                 \n","__________________________________________________________________________________________________\n","activation_288 (Activation)     (None, 25, 25, 48)   0           batch_normalization_290[0][0]    \n","__________________________________________________________________________________________________\n","activation_291 (Activation)     (None, 25, 25, 96)   0           batch_normalization_293[0][0]    \n","__________________________________________________________________________________________________\n","average_pooling2d_27 (AveragePo (None, 25, 25, 192)  0           max_pooling2d_13[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_287 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_13[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_289 (Conv2D)             (None, 25, 25, 64)   76800       activation_288[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_292 (Conv2D)             (None, 25, 25, 96)   82944       activation_291[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_293 (Conv2D)             (None, 25, 25, 32)   6144        average_pooling2d_27[0][0]       \n","__________________________________________________________________________________________________\n","batch_normalization_289 (BatchN (None, 25, 25, 64)   192         conv2d_287[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_291 (BatchN (None, 25, 25, 64)   192         conv2d_289[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_294 (BatchN (None, 25, 25, 96)   288         conv2d_292[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_295 (BatchN (None, 25, 25, 32)   96          conv2d_293[0][0]                 \n","__________________________________________________________________________________________________\n","activation_287 (Activation)     (None, 25, 25, 64)   0           batch_normalization_289[0][0]    \n","__________________________________________________________________________________________________\n","activation_289 (Activation)     (None, 25, 25, 64)   0           batch_normalization_291[0][0]    \n","__________________________________________________________________________________________________\n","activation_292 (Activation)     (None, 25, 25, 96)   0           batch_normalization_294[0][0]    \n","__________________________________________________________________________________________________\n","activation_293 (Activation)     (None, 25, 25, 32)   0           batch_normalization_295[0][0]    \n","__________________________________________________________________________________________________\n","mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_287[0][0]             \n","                                                                 activation_289[0][0]             \n","                                                                 activation_292[0][0]             \n","                                                                 activation_293[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_297 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_299 (BatchN (None, 25, 25, 64)   192         conv2d_297[0][0]                 \n","__________________________________________________________________________________________________\n","activation_297 (Activation)     (None, 25, 25, 64)   0           batch_normalization_299[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_295 (Conv2D)             (None, 25, 25, 48)   12288       mixed0[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_298 (Conv2D)             (None, 25, 25, 96)   55296       activation_297[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_297 (BatchN (None, 25, 25, 48)   144         conv2d_295[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_300 (BatchN (None, 25, 25, 96)   288         conv2d_298[0][0]                 \n","__________________________________________________________________________________________________\n","activation_295 (Activation)     (None, 25, 25, 48)   0           batch_normalization_297[0][0]    \n","__________________________________________________________________________________________________\n","activation_298 (Activation)     (None, 25, 25, 96)   0           batch_normalization_300[0][0]    \n","__________________________________________________________________________________________________\n","average_pooling2d_28 (AveragePo (None, 25, 25, 256)  0           mixed0[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_294 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_296 (Conv2D)             (None, 25, 25, 64)   76800       activation_295[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_299 (Conv2D)             (None, 25, 25, 96)   82944       activation_298[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_300 (Conv2D)             (None, 25, 25, 64)   16384       average_pooling2d_28[0][0]       \n","__________________________________________________________________________________________________\n","batch_normalization_296 (BatchN (None, 25, 25, 64)   192         conv2d_294[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_298 (BatchN (None, 25, 25, 64)   192         conv2d_296[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_301 (BatchN (None, 25, 25, 96)   288         conv2d_299[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_302 (BatchN (None, 25, 25, 64)   192         conv2d_300[0][0]                 \n","__________________________________________________________________________________________________\n","activation_294 (Activation)     (None, 25, 25, 64)   0           batch_normalization_296[0][0]    \n","__________________________________________________________________________________________________\n","activation_296 (Activation)     (None, 25, 25, 64)   0           batch_normalization_298[0][0]    \n","__________________________________________________________________________________________________\n","activation_299 (Activation)     (None, 25, 25, 96)   0           batch_normalization_301[0][0]    \n","__________________________________________________________________________________________________\n","activation_300 (Activation)     (None, 25, 25, 64)   0           batch_normalization_302[0][0]    \n","__________________________________________________________________________________________________\n","mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_294[0][0]             \n","                                                                 activation_296[0][0]             \n","                                                                 activation_299[0][0]             \n","                                                                 activation_300[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_304 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_306 (BatchN (None, 25, 25, 64)   192         conv2d_304[0][0]                 \n","__________________________________________________________________________________________________\n","activation_304 (Activation)     (None, 25, 25, 64)   0           batch_normalization_306[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_302 (Conv2D)             (None, 25, 25, 48)   13824       mixed1[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_305 (Conv2D)             (None, 25, 25, 96)   55296       activation_304[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_304 (BatchN (None, 25, 25, 48)   144         conv2d_302[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_307 (BatchN (None, 25, 25, 96)   288         conv2d_305[0][0]                 \n","__________________________________________________________________________________________________\n","activation_302 (Activation)     (None, 25, 25, 48)   0           batch_normalization_304[0][0]    \n","__________________________________________________________________________________________________\n","activation_305 (Activation)     (None, 25, 25, 96)   0           batch_normalization_307[0][0]    \n","__________________________________________________________________________________________________\n","average_pooling2d_29 (AveragePo (None, 25, 25, 288)  0           mixed1[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_301 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_303 (Conv2D)             (None, 25, 25, 64)   76800       activation_302[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_306 (Conv2D)             (None, 25, 25, 96)   82944       activation_305[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_307 (Conv2D)             (None, 25, 25, 64)   18432       average_pooling2d_29[0][0]       \n","__________________________________________________________________________________________________\n","batch_normalization_303 (BatchN (None, 25, 25, 64)   192         conv2d_301[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_305 (BatchN (None, 25, 25, 64)   192         conv2d_303[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_308 (BatchN (None, 25, 25, 96)   288         conv2d_306[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_309 (BatchN (None, 25, 25, 64)   192         conv2d_307[0][0]                 \n","__________________________________________________________________________________________________\n","activation_301 (Activation)     (None, 25, 25, 64)   0           batch_normalization_303[0][0]    \n","__________________________________________________________________________________________________\n","activation_303 (Activation)     (None, 25, 25, 64)   0           batch_normalization_305[0][0]    \n","__________________________________________________________________________________________________\n","activation_306 (Activation)     (None, 25, 25, 96)   0           batch_normalization_308[0][0]    \n","__________________________________________________________________________________________________\n","activation_307 (Activation)     (None, 25, 25, 64)   0           batch_normalization_309[0][0]    \n","__________________________________________________________________________________________________\n","mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_301[0][0]             \n","                                                                 activation_303[0][0]             \n","                                                                 activation_306[0][0]             \n","                                                                 activation_307[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_309 (Conv2D)             (None, 25, 25, 64)   18432       mixed2[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_311 (BatchN (None, 25, 25, 64)   192         conv2d_309[0][0]                 \n","__________________________________________________________________________________________________\n","activation_309 (Activation)     (None, 25, 25, 64)   0           batch_normalization_311[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_310 (Conv2D)             (None, 25, 25, 96)   55296       activation_309[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_312 (BatchN (None, 25, 25, 96)   288         conv2d_310[0][0]                 \n","__________________________________________________________________________________________________\n","activation_310 (Activation)     (None, 25, 25, 96)   0           batch_normalization_312[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_308 (Conv2D)             (None, 12, 12, 384)  995328      mixed2[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_311 (Conv2D)             (None, 12, 12, 96)   82944       activation_310[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_310 (BatchN (None, 12, 12, 384)  1152        conv2d_308[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_313 (BatchN (None, 12, 12, 96)   288         conv2d_311[0][0]                 \n","__________________________________________________________________________________________________\n","activation_308 (Activation)     (None, 12, 12, 384)  0           batch_normalization_310[0][0]    \n","__________________________________________________________________________________________________\n","activation_311 (Activation)     (None, 12, 12, 96)   0           batch_normalization_313[0][0]    \n","__________________________________________________________________________________________________\n","max_pooling2d_14 (MaxPooling2D) (None, 12, 12, 288)  0           mixed2[0][0]                     \n","__________________________________________________________________________________________________\n","mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_308[0][0]             \n","                                                                 activation_311[0][0]             \n","                                                                 max_pooling2d_14[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_316 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_318 (BatchN (None, 12, 12, 128)  384         conv2d_316[0][0]                 \n","__________________________________________________________________________________________________\n","activation_316 (Activation)     (None, 12, 12, 128)  0           batch_normalization_318[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_317 (Conv2D)             (None, 12, 12, 128)  114688      activation_316[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_319 (BatchN (None, 12, 12, 128)  384         conv2d_317[0][0]                 \n","__________________________________________________________________________________________________\n","activation_317 (Activation)     (None, 12, 12, 128)  0           batch_normalization_319[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_313 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_318 (Conv2D)             (None, 12, 12, 128)  114688      activation_317[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_315 (BatchN (None, 12, 12, 128)  384         conv2d_313[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_320 (BatchN (None, 12, 12, 128)  384         conv2d_318[0][0]                 \n","__________________________________________________________________________________________________\n","activation_313 (Activation)     (None, 12, 12, 128)  0           batch_normalization_315[0][0]    \n","__________________________________________________________________________________________________\n","activation_318 (Activation)     (None, 12, 12, 128)  0           batch_normalization_320[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_314 (Conv2D)             (None, 12, 12, 128)  114688      activation_313[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_319 (Conv2D)             (None, 12, 12, 128)  114688      activation_318[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_316 (BatchN (None, 12, 12, 128)  384         conv2d_314[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_321 (BatchN (None, 12, 12, 128)  384         conv2d_319[0][0]                 \n","__________________________________________________________________________________________________\n","activation_314 (Activation)     (None, 12, 12, 128)  0           batch_normalization_316[0][0]    \n","__________________________________________________________________________________________________\n","activation_319 (Activation)     (None, 12, 12, 128)  0           batch_normalization_321[0][0]    \n","__________________________________________________________________________________________________\n","average_pooling2d_30 (AveragePo (None, 12, 12, 768)  0           mixed3[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_312 (Conv2D)             (None, 12, 12, 192)  147456      mixed3[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_315 (Conv2D)             (None, 12, 12, 192)  172032      activation_314[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_320 (Conv2D)             (None, 12, 12, 192)  172032      activation_319[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_321 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_30[0][0]       \n","__________________________________________________________________________________________________\n","batch_normalization_314 (BatchN (None, 12, 12, 192)  576         conv2d_312[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_317 (BatchN (None, 12, 12, 192)  576         conv2d_315[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_322 (BatchN (None, 12, 12, 192)  576         conv2d_320[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_323 (BatchN (None, 12, 12, 192)  576         conv2d_321[0][0]                 \n","__________________________________________________________________________________________________\n","activation_312 (Activation)     (None, 12, 12, 192)  0           batch_normalization_314[0][0]    \n","__________________________________________________________________________________________________\n","activation_315 (Activation)     (None, 12, 12, 192)  0           batch_normalization_317[0][0]    \n","__________________________________________________________________________________________________\n","activation_320 (Activation)     (None, 12, 12, 192)  0           batch_normalization_322[0][0]    \n","__________________________________________________________________________________________________\n","activation_321 (Activation)     (None, 12, 12, 192)  0           batch_normalization_323[0][0]    \n","__________________________________________________________________________________________________\n","mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_312[0][0]             \n","                                                                 activation_315[0][0]             \n","                                                                 activation_320[0][0]             \n","                                                                 activation_321[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_326 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_328 (BatchN (None, 12, 12, 160)  480         conv2d_326[0][0]                 \n","__________________________________________________________________________________________________\n","activation_326 (Activation)     (None, 12, 12, 160)  0           batch_normalization_328[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_327 (Conv2D)             (None, 12, 12, 160)  179200      activation_326[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_329 (BatchN (None, 12, 12, 160)  480         conv2d_327[0][0]                 \n","__________________________________________________________________________________________________\n","activation_327 (Activation)     (None, 12, 12, 160)  0           batch_normalization_329[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_323 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_328 (Conv2D)             (None, 12, 12, 160)  179200      activation_327[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_325 (BatchN (None, 12, 12, 160)  480         conv2d_323[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_330 (BatchN (None, 12, 12, 160)  480         conv2d_328[0][0]                 \n","__________________________________________________________________________________________________\n","activation_323 (Activation)     (None, 12, 12, 160)  0           batch_normalization_325[0][0]    \n","__________________________________________________________________________________________________\n","activation_328 (Activation)     (None, 12, 12, 160)  0           batch_normalization_330[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_324 (Conv2D)             (None, 12, 12, 160)  179200      activation_323[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_329 (Conv2D)             (None, 12, 12, 160)  179200      activation_328[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_326 (BatchN (None, 12, 12, 160)  480         conv2d_324[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_331 (BatchN (None, 12, 12, 160)  480         conv2d_329[0][0]                 \n","__________________________________________________________________________________________________\n","activation_324 (Activation)     (None, 12, 12, 160)  0           batch_normalization_326[0][0]    \n","__________________________________________________________________________________________________\n","activation_329 (Activation)     (None, 12, 12, 160)  0           batch_normalization_331[0][0]    \n","__________________________________________________________________________________________________\n","average_pooling2d_31 (AveragePo (None, 12, 12, 768)  0           mixed4[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_322 (Conv2D)             (None, 12, 12, 192)  147456      mixed4[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_325 (Conv2D)             (None, 12, 12, 192)  215040      activation_324[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_330 (Conv2D)             (None, 12, 12, 192)  215040      activation_329[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_331 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_31[0][0]       \n","__________________________________________________________________________________________________\n","batch_normalization_324 (BatchN (None, 12, 12, 192)  576         conv2d_322[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_327 (BatchN (None, 12, 12, 192)  576         conv2d_325[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_332 (BatchN (None, 12, 12, 192)  576         conv2d_330[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_333 (BatchN (None, 12, 12, 192)  576         conv2d_331[0][0]                 \n","__________________________________________________________________________________________________\n","activation_322 (Activation)     (None, 12, 12, 192)  0           batch_normalization_324[0][0]    \n","__________________________________________________________________________________________________\n","activation_325 (Activation)     (None, 12, 12, 192)  0           batch_normalization_327[0][0]    \n","__________________________________________________________________________________________________\n","activation_330 (Activation)     (None, 12, 12, 192)  0           batch_normalization_332[0][0]    \n","__________________________________________________________________________________________________\n","activation_331 (Activation)     (None, 12, 12, 192)  0           batch_normalization_333[0][0]    \n","__________________________________________________________________________________________________\n","mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_322[0][0]             \n","                                                                 activation_325[0][0]             \n","                                                                 activation_330[0][0]             \n","                                                                 activation_331[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_336 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_338 (BatchN (None, 12, 12, 160)  480         conv2d_336[0][0]                 \n","__________________________________________________________________________________________________\n","activation_336 (Activation)     (None, 12, 12, 160)  0           batch_normalization_338[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_337 (Conv2D)             (None, 12, 12, 160)  179200      activation_336[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_339 (BatchN (None, 12, 12, 160)  480         conv2d_337[0][0]                 \n","__________________________________________________________________________________________________\n","activation_337 (Activation)     (None, 12, 12, 160)  0           batch_normalization_339[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_333 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_338 (Conv2D)             (None, 12, 12, 160)  179200      activation_337[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_335 (BatchN (None, 12, 12, 160)  480         conv2d_333[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_340 (BatchN (None, 12, 12, 160)  480         conv2d_338[0][0]                 \n","__________________________________________________________________________________________________\n","activation_333 (Activation)     (None, 12, 12, 160)  0           batch_normalization_335[0][0]    \n","__________________________________________________________________________________________________\n","activation_338 (Activation)     (None, 12, 12, 160)  0           batch_normalization_340[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_334 (Conv2D)             (None, 12, 12, 160)  179200      activation_333[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_339 (Conv2D)             (None, 12, 12, 160)  179200      activation_338[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_336 (BatchN (None, 12, 12, 160)  480         conv2d_334[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_341 (BatchN (None, 12, 12, 160)  480         conv2d_339[0][0]                 \n","__________________________________________________________________________________________________\n","activation_334 (Activation)     (None, 12, 12, 160)  0           batch_normalization_336[0][0]    \n","__________________________________________________________________________________________________\n","activation_339 (Activation)     (None, 12, 12, 160)  0           batch_normalization_341[0][0]    \n","__________________________________________________________________________________________________\n","average_pooling2d_32 (AveragePo (None, 12, 12, 768)  0           mixed5[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_332 (Conv2D)             (None, 12, 12, 192)  147456      mixed5[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_335 (Conv2D)             (None, 12, 12, 192)  215040      activation_334[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_340 (Conv2D)             (None, 12, 12, 192)  215040      activation_339[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_341 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_32[0][0]       \n","__________________________________________________________________________________________________\n","batch_normalization_334 (BatchN (None, 12, 12, 192)  576         conv2d_332[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_337 (BatchN (None, 12, 12, 192)  576         conv2d_335[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_342 (BatchN (None, 12, 12, 192)  576         conv2d_340[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_343 (BatchN (None, 12, 12, 192)  576         conv2d_341[0][0]                 \n","__________________________________________________________________________________________________\n","activation_332 (Activation)     (None, 12, 12, 192)  0           batch_normalization_334[0][0]    \n","__________________________________________________________________________________________________\n","activation_335 (Activation)     (None, 12, 12, 192)  0           batch_normalization_337[0][0]    \n","__________________________________________________________________________________________________\n","activation_340 (Activation)     (None, 12, 12, 192)  0           batch_normalization_342[0][0]    \n","__________________________________________________________________________________________________\n","activation_341 (Activation)     (None, 12, 12, 192)  0           batch_normalization_343[0][0]    \n","__________________________________________________________________________________________________\n","mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_332[0][0]             \n","                                                                 activation_335[0][0]             \n","                                                                 activation_340[0][0]             \n","                                                                 activation_341[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_346 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_348 (BatchN (None, 12, 12, 192)  576         conv2d_346[0][0]                 \n","__________________________________________________________________________________________________\n","activation_346 (Activation)     (None, 12, 12, 192)  0           batch_normalization_348[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_347 (Conv2D)             (None, 12, 12, 192)  258048      activation_346[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_349 (BatchN (None, 12, 12, 192)  576         conv2d_347[0][0]                 \n","__________________________________________________________________________________________________\n","activation_347 (Activation)     (None, 12, 12, 192)  0           batch_normalization_349[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_343 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_348 (Conv2D)             (None, 12, 12, 192)  258048      activation_347[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_345 (BatchN (None, 12, 12, 192)  576         conv2d_343[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_350 (BatchN (None, 12, 12, 192)  576         conv2d_348[0][0]                 \n","__________________________________________________________________________________________________\n","activation_343 (Activation)     (None, 12, 12, 192)  0           batch_normalization_345[0][0]    \n","__________________________________________________________________________________________________\n","activation_348 (Activation)     (None, 12, 12, 192)  0           batch_normalization_350[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_344 (Conv2D)             (None, 12, 12, 192)  258048      activation_343[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_349 (Conv2D)             (None, 12, 12, 192)  258048      activation_348[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_346 (BatchN (None, 12, 12, 192)  576         conv2d_344[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_351 (BatchN (None, 12, 12, 192)  576         conv2d_349[0][0]                 \n","__________________________________________________________________________________________________\n","activation_344 (Activation)     (None, 12, 12, 192)  0           batch_normalization_346[0][0]    \n","__________________________________________________________________________________________________\n","activation_349 (Activation)     (None, 12, 12, 192)  0           batch_normalization_351[0][0]    \n","__________________________________________________________________________________________________\n","average_pooling2d_33 (AveragePo (None, 12, 12, 768)  0           mixed6[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_342 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_345 (Conv2D)             (None, 12, 12, 192)  258048      activation_344[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_350 (Conv2D)             (None, 12, 12, 192)  258048      activation_349[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_351 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_33[0][0]       \n","__________________________________________________________________________________________________\n","batch_normalization_344 (BatchN (None, 12, 12, 192)  576         conv2d_342[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_347 (BatchN (None, 12, 12, 192)  576         conv2d_345[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_352 (BatchN (None, 12, 12, 192)  576         conv2d_350[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_353 (BatchN (None, 12, 12, 192)  576         conv2d_351[0][0]                 \n","__________________________________________________________________________________________________\n","activation_342 (Activation)     (None, 12, 12, 192)  0           batch_normalization_344[0][0]    \n","__________________________________________________________________________________________________\n","activation_345 (Activation)     (None, 12, 12, 192)  0           batch_normalization_347[0][0]    \n","__________________________________________________________________________________________________\n","activation_350 (Activation)     (None, 12, 12, 192)  0           batch_normalization_352[0][0]    \n","__________________________________________________________________________________________________\n","activation_351 (Activation)     (None, 12, 12, 192)  0           batch_normalization_353[0][0]    \n","__________________________________________________________________________________________________\n","mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_342[0][0]             \n","                                                                 activation_345[0][0]             \n","                                                                 activation_350[0][0]             \n","                                                                 activation_351[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_354 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_356 (BatchN (None, 12, 12, 192)  576         conv2d_354[0][0]                 \n","__________________________________________________________________________________________________\n","activation_354 (Activation)     (None, 12, 12, 192)  0           batch_normalization_356[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_355 (Conv2D)             (None, 12, 12, 192)  258048      activation_354[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_357 (BatchN (None, 12, 12, 192)  576         conv2d_355[0][0]                 \n","__________________________________________________________________________________________________\n","activation_355 (Activation)     (None, 12, 12, 192)  0           batch_normalization_357[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_352 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_356 (Conv2D)             (None, 12, 12, 192)  258048      activation_355[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_354 (BatchN (None, 12, 12, 192)  576         conv2d_352[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_358 (BatchN (None, 12, 12, 192)  576         conv2d_356[0][0]                 \n","__________________________________________________________________________________________________\n","activation_352 (Activation)     (None, 12, 12, 192)  0           batch_normalization_354[0][0]    \n","__________________________________________________________________________________________________\n","activation_356 (Activation)     (None, 12, 12, 192)  0           batch_normalization_358[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_353 (Conv2D)             (None, 5, 5, 320)    552960      activation_352[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_357 (Conv2D)             (None, 5, 5, 192)    331776      activation_356[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_355 (BatchN (None, 5, 5, 320)    960         conv2d_353[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_359 (BatchN (None, 5, 5, 192)    576         conv2d_357[0][0]                 \n","__________________________________________________________________________________________________\n","activation_353 (Activation)     (None, 5, 5, 320)    0           batch_normalization_355[0][0]    \n","__________________________________________________________________________________________________\n","activation_357 (Activation)     (None, 5, 5, 192)    0           batch_normalization_359[0][0]    \n","__________________________________________________________________________________________________\n","max_pooling2d_15 (MaxPooling2D) (None, 5, 5, 768)    0           mixed7[0][0]                     \n","__________________________________________________________________________________________________\n","mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_353[0][0]             \n","                                                                 activation_357[0][0]             \n","                                                                 max_pooling2d_15[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_362 (Conv2D)             (None, 5, 5, 448)    573440      mixed8[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_364 (BatchN (None, 5, 5, 448)    1344        conv2d_362[0][0]                 \n","__________________________________________________________________________________________________\n","activation_362 (Activation)     (None, 5, 5, 448)    0           batch_normalization_364[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_359 (Conv2D)             (None, 5, 5, 384)    491520      mixed8[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_363 (Conv2D)             (None, 5, 5, 384)    1548288     activation_362[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_361 (BatchN (None, 5, 5, 384)    1152        conv2d_359[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_365 (BatchN (None, 5, 5, 384)    1152        conv2d_363[0][0]                 \n","__________________________________________________________________________________________________\n","activation_359 (Activation)     (None, 5, 5, 384)    0           batch_normalization_361[0][0]    \n","__________________________________________________________________________________________________\n","activation_363 (Activation)     (None, 5, 5, 384)    0           batch_normalization_365[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_360 (Conv2D)             (None, 5, 5, 384)    442368      activation_359[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_361 (Conv2D)             (None, 5, 5, 384)    442368      activation_359[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_364 (Conv2D)             (None, 5, 5, 384)    442368      activation_363[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_365 (Conv2D)             (None, 5, 5, 384)    442368      activation_363[0][0]             \n","__________________________________________________________________________________________________\n","average_pooling2d_34 (AveragePo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_358 (Conv2D)             (None, 5, 5, 320)    409600      mixed8[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_362 (BatchN (None, 5, 5, 384)    1152        conv2d_360[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_363 (BatchN (None, 5, 5, 384)    1152        conv2d_361[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_366 (BatchN (None, 5, 5, 384)    1152        conv2d_364[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_367 (BatchN (None, 5, 5, 384)    1152        conv2d_365[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_366 (Conv2D)             (None, 5, 5, 192)    245760      average_pooling2d_34[0][0]       \n","__________________________________________________________________________________________________\n","batch_normalization_360 (BatchN (None, 5, 5, 320)    960         conv2d_358[0][0]                 \n","__________________________________________________________________________________________________\n","activation_360 (Activation)     (None, 5, 5, 384)    0           batch_normalization_362[0][0]    \n","__________________________________________________________________________________________________\n","activation_361 (Activation)     (None, 5, 5, 384)    0           batch_normalization_363[0][0]    \n","__________________________________________________________________________________________________\n","activation_364 (Activation)     (None, 5, 5, 384)    0           batch_normalization_366[0][0]    \n","__________________________________________________________________________________________________\n","activation_365 (Activation)     (None, 5, 5, 384)    0           batch_normalization_367[0][0]    \n","__________________________________________________________________________________________________\n","batch_normalization_368 (BatchN (None, 5, 5, 192)    576         conv2d_366[0][0]                 \n","__________________________________________________________________________________________________\n","activation_358 (Activation)     (None, 5, 5, 320)    0           batch_normalization_360[0][0]    \n","__________________________________________________________________________________________________\n","mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_360[0][0]             \n","                                                                 activation_361[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_6 (Concatenate)     (None, 5, 5, 768)    0           activation_364[0][0]             \n","                                                                 activation_365[0][0]             \n","__________________________________________________________________________________________________\n","activation_366 (Activation)     (None, 5, 5, 192)    0           batch_normalization_368[0][0]    \n","__________________________________________________________________________________________________\n","mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_358[0][0]             \n","                                                                 mixed9_0[0][0]                   \n","                                                                 concatenate_6[0][0]              \n","                                                                 activation_366[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_371 (Conv2D)             (None, 5, 5, 448)    917504      mixed9[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_373 (BatchN (None, 5, 5, 448)    1344        conv2d_371[0][0]                 \n","__________________________________________________________________________________________________\n","activation_371 (Activation)     (None, 5, 5, 448)    0           batch_normalization_373[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_368 (Conv2D)             (None, 5, 5, 384)    786432      mixed9[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_372 (Conv2D)             (None, 5, 5, 384)    1548288     activation_371[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_370 (BatchN (None, 5, 5, 384)    1152        conv2d_368[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_374 (BatchN (None, 5, 5, 384)    1152        conv2d_372[0][0]                 \n","__________________________________________________________________________________________________\n","activation_368 (Activation)     (None, 5, 5, 384)    0           batch_normalization_370[0][0]    \n","__________________________________________________________________________________________________\n","activation_372 (Activation)     (None, 5, 5, 384)    0           batch_normalization_374[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_369 (Conv2D)             (None, 5, 5, 384)    442368      activation_368[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_370 (Conv2D)             (None, 5, 5, 384)    442368      activation_368[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_373 (Conv2D)             (None, 5, 5, 384)    442368      activation_372[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_374 (Conv2D)             (None, 5, 5, 384)    442368      activation_372[0][0]             \n","__________________________________________________________________________________________________\n","average_pooling2d_35 (AveragePo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_367 (Conv2D)             (None, 5, 5, 320)    655360      mixed9[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_371 (BatchN (None, 5, 5, 384)    1152        conv2d_369[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_372 (BatchN (None, 5, 5, 384)    1152        conv2d_370[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_375 (BatchN (None, 5, 5, 384)    1152        conv2d_373[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_376 (BatchN (None, 5, 5, 384)    1152        conv2d_374[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_375 (Conv2D)             (None, 5, 5, 192)    393216      average_pooling2d_35[0][0]       \n","__________________________________________________________________________________________________\n","batch_normalization_369 (BatchN (None, 5, 5, 320)    960         conv2d_367[0][0]                 \n","__________________________________________________________________________________________________\n","activation_369 (Activation)     (None, 5, 5, 384)    0           batch_normalization_371[0][0]    \n","__________________________________________________________________________________________________\n","activation_370 (Activation)     (None, 5, 5, 384)    0           batch_normalization_372[0][0]    \n","__________________________________________________________________________________________________\n","activation_373 (Activation)     (None, 5, 5, 384)    0           batch_normalization_375[0][0]    \n","__________________________________________________________________________________________________\n","activation_374 (Activation)     (None, 5, 5, 384)    0           batch_normalization_376[0][0]    \n","__________________________________________________________________________________________________\n","batch_normalization_377 (BatchN (None, 5, 5, 192)    576         conv2d_375[0][0]                 \n","__________________________________________________________________________________________________\n","activation_367 (Activation)     (None, 5, 5, 320)    0           batch_normalization_369[0][0]    \n","__________________________________________________________________________________________________\n","mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_369[0][0]             \n","                                                                 activation_370[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_7 (Concatenate)     (None, 5, 5, 768)    0           activation_373[0][0]             \n","                                                                 activation_374[0][0]             \n","__________________________________________________________________________________________________\n","activation_375 (Activation)     (None, 5, 5, 192)    0           batch_normalization_377[0][0]    \n","__________________________________________________________________________________________________\n","mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_367[0][0]             \n","                                                                 mixed9_1[0][0]                   \n","                                                                 concatenate_7[0][0]              \n","                                                                 activation_375[0][0]             \n","==================================================================================================\n","Total params: 21,802,784\n","Trainable params: 0\n","Non-trainable params: 21,802,784\n","__________________________________________________________________________________________________\n"],"name":"stdout"},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-e0a3eeec9000>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m+\u001b[0m\u001b[0minception_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: bad operand type for unary +: 'NoneType'"]}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TP28VePeWN-a","colab":{}},"source":["from tensorflow.keras import models\n","import numpy as np\n","from keras.preprocessing import image\n","\n","test_image = image.load_img('/content/drive/My Drive/Colab Notebooks/Object Classification1/Validation Set/Headphone/images (1).jpg', target_size = (150, 150))\n","test_image = image.img_to_array(test_image)\n","test_image = np.expand_dims(test_image, axis = 0)\n","model = models.load_model('/content/drive/My Drive/Colab Notebooks/Object Classification1/InceptionNet_Experiment4.h5')\n","result = model.predict(test_image)\n","print(result[0][0])\n","#training_set.class_indices\n","if result[0][0] == 1:\n","    prediction = 'Headphone'\n","    print(prediction)\n","elif result[0][1] == 1:\n","    prediction = 'Keyboard'\n","    print(prediction)\n","elif result[0][2] == 1:\n","    prediction = 'Laptop'\n","    print(prediction)\n","elif result[0][3] == 1:\n","    prediction = 'Mobile'\n","    print(prediction)\n","else:\n","    prediction = 'Mouse'\n","    print(prediction)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ArryS-nKWO4u"},"source":["Test Whether GPU is working?"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3n94c2epFzxc","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":11266,"status":"ok","timestamp":1592782295771,"user":{"displayName":"SUMIT KUMAR Mishra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8L9OOk0XAmThI6JjfNERxhl4nk0tkwomeiGGDcw=s64","userId":"14062024626619512347"},"user_tz":-330},"outputId":"ca9cc10e-1788-4ecb-e80d-aff6bc899715"},"source":["import tensorflow as tf\n","tf.test.gpu_device_name()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iG2t7Cd0Qdg5","colab":{"base_uri":"https://localhost:8080/","height":180},"executionInfo":{"elapsed":1910,"status":"error","timestamp":1592782882366,"user":{"displayName":"SUMIT KUMAR Mishra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8L9OOk0XAmThI6JjfNERxhl4nk0tkwomeiGGDcw=s64","userId":"14062024626619512347"},"user_tz":-330},"outputId":"c0ddc4a6-c7c1-4c93-e69f-04f5e38ea400"},"source":["import tensorflow as tf\n","tf.test.tpu_device_name()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-f4dcb5f51a3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.test' has no attribute 'tpu_device_name'"]}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qybmYPAhWnaS"},"source":["Which GPU we are using?"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rc6dXC53FtSw","colab":{"base_uri":"https://localhost:8080/","height":476},"executionInfo":{"elapsed":1586,"status":"ok","timestamp":1592782304701,"user":{"displayName":"SUMIT KUMAR Mishra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8L9OOk0XAmThI6JjfNERxhl4nk0tkwomeiGGDcw=s64","userId":"14062024626619512347"},"user_tz":-330},"outputId":"3027525b-6dfe-4e54-ccb1-11332d4966ce"},"source":["from tensorflow.python.client import device_lib\n","device_lib.list_local_devices()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[name: \"/device:CPU:0\"\n"," device_type: \"CPU\"\n"," memory_limit: 268435456\n"," locality {\n"," }\n"," incarnation: 4525774508651259468, name: \"/device:XLA_CPU:0\"\n"," device_type: \"XLA_CPU\"\n"," memory_limit: 17179869184\n"," locality {\n"," }\n"," incarnation: 4646176974541834230\n"," physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n"," device_type: \"XLA_GPU\"\n"," memory_limit: 17179869184\n"," locality {\n"," }\n"," incarnation: 13842703055481781806\n"," physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n"," device_type: \"GPU\"\n"," memory_limit: 14648777152\n"," locality {\n","   bus_id: 1\n","   links {\n","   }\n"," }\n"," incarnation: 3732169469368498949\n"," physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"]"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Jk2Xk3T7XLDz"},"source":["RAM Information?"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IXIaEShFWEaM","colab":{"base_uri":"https://localhost:8080/","height":816},"executionInfo":{"elapsed":3642,"status":"ok","timestamp":1592516262474,"user":{"displayName":"SUMIT KUMAR Mishra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8L9OOk0XAmThI6JjfNERxhl4nk0tkwomeiGGDcw=s64","userId":"14062024626619512347"},"user_tz":-330},"outputId":"50cb9b66-df30-40b6-fe65-9e577437a8a3"},"source":["!cat /proc/meminfo"],"execution_count":null,"outputs":[{"output_type":"stream","text":["MemTotal:       13333556 kB\n","MemFree:         9142956 kB\n","MemAvailable:   11862616 kB\n","Buffers:           79480 kB\n","Cached:          2750336 kB\n","SwapCached:            0 kB\n","Active:          1216292 kB\n","Inactive:        2553924 kB\n","Active(anon):     866516 kB\n","Inactive(anon):     8528 kB\n","Active(file):     349776 kB\n","Inactive(file):  2545396 kB\n","Unevictable:           0 kB\n","Mlocked:               0 kB\n","SwapTotal:             0 kB\n","SwapFree:              0 kB\n","Dirty:               672 kB\n","Writeback:             0 kB\n","AnonPages:        940400 kB\n","Mapped:           687748 kB\n","Shmem:              9140 kB\n","Slab:             177408 kB\n","SReclaimable:     130756 kB\n","SUnreclaim:        46652 kB\n","KernelStack:        4448 kB\n","PageTables:         9256 kB\n","NFS_Unstable:          0 kB\n","Bounce:                0 kB\n","WritebackTmp:          0 kB\n","CommitLimit:     6666776 kB\n","Committed_AS:    3517404 kB\n","VmallocTotal:   34359738367 kB\n","VmallocUsed:           0 kB\n","VmallocChunk:          0 kB\n","Percpu:              920 kB\n","AnonHugePages:         0 kB\n","ShmemHugePages:        0 kB\n","ShmemPmdMapped:        0 kB\n","HugePages_Total:       0\n","HugePages_Free:        0\n","HugePages_Rsvd:        0\n","HugePages_Surp:        0\n","Hugepagesize:       2048 kB\n","Hugetlb:               0 kB\n","DirectMap4k:      195772 kB\n","DirectMap2M:     7143424 kB\n","DirectMap1G:     8388608 kB\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"l3nJP_-uXc_n"},"source":["CPU Info?"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kjnIaib5XaoD","colab":{"base_uri":"https://localhost:8080/","height":955},"executionInfo":{"elapsed":3327,"status":"ok","timestamp":1592516324262,"user":{"displayName":"SUMIT KUMAR Mishra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8L9OOk0XAmThI6JjfNERxhl4nk0tkwomeiGGDcw=s64","userId":"14062024626619512347"},"user_tz":-330},"outputId":"93b13c71-5e95-4b79-cf10-36dc58bd3d3d"},"source":["!cat /proc/cpuinfo"],"execution_count":null,"outputs":[{"output_type":"stream","text":["processor\t: 0\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2300.000\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 2\n","core id\t\t: 0\n","cpu cores\t: 1\n","apicid\t\t: 0\n","initial apicid\t: 0\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit\n","bogomips\t: 4600.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 1\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2300.000\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 2\n","core id\t\t: 0\n","cpu cores\t: 1\n","apicid\t\t: 1\n","initial apicid\t: 1\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit\n","bogomips\t: 4600.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"P1RrljPYXp1l","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":4023,"status":"ok","timestamp":1592782330437,"user":{"displayName":"SUMIT KUMAR Mishra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8L9OOk0XAmThI6JjfNERxhl4nk0tkwomeiGGDcw=s64","userId":"14062024626619512347"},"user_tz":-330},"outputId":"e7ea74ff-6b2e-40d7-9977-ba6537c97fb7"},"source":["!nvidia smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/bin/bash: nvidia: command not found\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZpeLGvM_N_h6","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}